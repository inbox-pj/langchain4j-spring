spring.application.name=langchain4j-spring
server.port=8080

# Request size limits (security - prevent DoS)
spring.servlet.multipart.max-file-size=10MB
spring.servlet.multipart.max-request-size=10MB
server.max-http-request-header-size=20KB

# Graceful shutdown
server.shutdown=graceful
spring.lifecycle.timeout-per-shutdown-phase=30s

# Response compression
server.compression.enabled=true
server.compression.mime-types=application/json,application/xml,text/html,text/xml,text/plain
server.compression.min-response-size=1024

# H2 Database Configuration
spring.datasource.name=langchain4jdb
spring.datasource.url=jdbc:h2:mem:langchain4jdb;DB_CLOSE_DELAY=-1;DB_CLOSE_ON_EXIT=FALSE
spring.datasource.username=sa
spring.datasource.password=password
spring.datasource.driver-class-name=org.h2.Driver
spring.jpa.database-platform=org.hibernate.dialect.H2Dialect
spring.h2.console.enabled=true

# JPA Hibernate Configuration
spring.jpa.hibernate.ddl-auto=none
spring.jpa.show-sql=true
spring.jpa.generate-ddl=false
spring.jpa.open-in-view=false

# ============================================================
# OBSERVABILITY & MONITORING
# ============================================================

# Actuator Configuration
management.endpoints.web.exposure.include=health,info,metrics,prometheus,httptrace,loggers,env
management.endpoint.health.show-details=always
management.endpoint.health.probes.enabled=true
management.health.livenessState.enabled=true
management.health.readinessState.enabled=true

# Metrics Configuration (Prometheus)
management.prometheus.metrics.export.enabled=true
management.metrics.distribution.percentiles-histogram.http.server.requests=true
management.metrics.tags.application=${spring.application.name}
management.metrics.tags.environment=dev
management.metrics.enable.jvm=true
management.metrics.enable.process=true
management.metrics.enable.system=true
management.metrics.enable.tomcat=true
management.metrics.enable.hikaricp=true

# Distributed Tracing (Jaeger with OpenTelemetry)
management.tracing.enabled=true
management.tracing.sampling.probability=1.0
management.otlp.tracing.endpoint=http://localhost:4318/v1/traces
management.otlp.tracing.compression=gzip
management.otlp.tracing.timeout=10s
management.tracing.propagation.type=w3c
management.tracing.baggage.remote-fields=user-id,session-id,request-id
management.tracing.baggage.correlation.fields=user-id,session-id,request-id

# Observation Configuration
management.observations.key-values.application=${spring.application.name}
management.observations.annotations.enabled=true

# Application Info for Actuator /actuator/info
info.app.name=@project.name@
info.app.description=@project.description@
info.app.version=@project.version@
info.app.java.version=@java.version@
info.observability.tracing=Jaeger with OpenTelemetry
info.observability.metrics=Prometheus

# Logging Configuration (with trace IDs)
logging.pattern.console=%green(%d{HH:mm:ss.SSS}) %blue(%-5level) %red([%thread]) %yellow(%logger{15}) [%X{traceId:-},%X{spanId:-}] - %msg%n
logging.level.dev.langchain4j=DEBUG
logging.level.org.springframework.web=INFO
logging.level.org.springframework.boot=INFO
logging.level.io.micrometer=INFO
logging.level.io.opentelemetry=INFO
logging.level.io.opentelemetry.exporter=DEBUG

# Ollama Chat Model Configuration
langchain4j.ollama.chat-model.base-url=http://localhost:11434
langchain4j.ollama.chat-model.model-name=qwen3:0.6b
langchain4j.ollama.chat-model.temperature=0.7
langchain4j.ollama.chat-model.timeout=PT60S
langchain4j.ollama.chat-model.think=true
langchain4j.ollama.chat-model.top-p=0.9
langchain4j.ollama.chat-model.max-retries=2
langchain4j.ollama.chat-model.log-requests=true
langchain4j.ollama.chat-model.log-responses=true
langchain4j.ollama.chat-model.supported-capabilities=response_format_json_schema

# Ollama Embedding Model Configuration
langchain4j.ollama.embedding-model.base-url=${langchain4j.ollama.chat-model.base-url}
langchain4j.ollama.embedding-model.log-requests=true
langchain4j.ollama.embedding-model.log-responses=true
langchain4j.ollama.embedding-model.model-name=nomic-embed-text:latest
langchain4j.ollama.embedding-model.max-retries=2
langchain4j.ollama.embedding-model.timeout=PT60S

# Qdrant Vector Store Configuration
langchain4j.qdrant.host=localhost
langchain4j.qdrant.port=6334
langchain4j.qdrant.collection-name=story

# Flyway Configuration
spring.flyway.enabled=true
spring.flyway.locations=classpath:db/migration
spring.flyway.baseline-on-migrate=true
spring.flyway.validate-on-migrate=true
spring.flyway.out-of-order=false

# ============================================================
# LangChain4j Application Configuration
# ============================================================

# Chat Memory Settings
app.langchain4j.chat-memory.max-messages=10
app.langchain4j.chat-memory.persist-enabled=true

# RAG (Retrieval-Augmented Generation) Settings
app.langchain4j.rag.max-results=3
app.langchain4j.rag.min-score=0.75
app.langchain4j.rag.chunk-size=100
app.langchain4j.rag.chunk-overlap=0

# Document Metadata Settings
app.langchain4j.document.source=story-about-happy-carrot
app.langchain4j.document.author=pjaiswal
app.langchain4j.document.type=story
app.langchain4j.document.title=Happy Carrot
app.langchain4j.document.language=English

